"""Collection of functions to handle scoring of molecules in a dataframe."""

import pandas as pd
import streamlit as st

from navidiv.utils import (
    add_mean_of_numeric_columns,
    groupby_results,
    initialize_scorer,
)


def cumulative_unique_count(list_of_lists):
    seen = set()
    counts = []
    for fragments in list_of_lists:
        seen.update(fragments)
        counts.append(len(seen))
    return counts


def run_scorer_on_dataframe(
    data,
    scorer_name,
    steps,
    scorer_props,
):
    # Generated by Copilot
    # Dynamically import scorer modules
    scorer = initialize_scorer(scorer_props)
    scores_list = []
    succesfull_steps = []
    score_status_placeholder = st.sidebar.empty()  # Generated by Copilot

    for step in steps:
        if hasattr(scorer, "_mol_smiles"):
            delattr(scorer, "_mol_smiles")
        df_copy = data[data["step"] == step]
        if df_copy.empty:
            continue
        smiles_list = df_copy["SMILES"].tolist()
        scores = df_copy["Score"].tolist()
        try:
            scores_result = scorer.get_score(
                smiles_list=smiles_list,
                scores=scores,
                additional_columns_df={"step": step},
            )
            scores_list.append(scores_result)
            succesfull_steps.append(step)
        except Exception as e:
            st.error(f"Scorer error in '{scorer_name}' at step {step}: {e}")
            continue
        scores_result_copy = scores_result.copy()
        scores_result_copy.pop("Unique Fragments")
        score_status_placeholder.write(
            f"### Scoring step {step} for {scorer_name} completed. Scores: {scores_result_copy}",
        )
    if scores_list:
        df_scores = pd.DataFrame(scores_list)

        df_scores["Cumulative Number of unique Fragments"] = (
            cumulative_unique_count(df_scores["Unique Fragments"].tolist())
        )
        df_scores["Cumulative Number of Fragments"] = df_scores[
            "Total Number of Fragments"
        ].cumsum()
        df_scores["Cumulative Percentage of Unique Fragments"] = (
            df_scores["Cumulative Number of unique Fragments"]
            / df_scores["Cumulative Number of Fragments"]
        ) * 100
        df_scores = df_scores.drop("Unique Fragments", axis=1, errors="ignore")
        dict_mean = add_mean_of_numeric_columns(data, succesfull_steps)
        for col, mean in dict_mean.items():
            df_scores[col] = mean
        # df_scores["step"] = steps

        df_scores.to_csv(
            f"{st.session_state.output_path}/{scorer._csv_name}/step_scores_{scorer._csv_name}.csv",
            index=False,
        )
        df_fragments = pd.read_csv(
            f"{st.session_state.output_path}/{scorer._csv_name}/{scorer._csv_name}_with_score.csv",
            index_col=False,
        )
        try:
            groupby_results_df = groupby_results(df_fragments)
            groupby_results_df.to_csv(
                f"{st.session_state.output_path}/{scorer._csv_name}/groupby_results_{scorer._csv_name}.csv",
                index=False,
            )
        except Exception as e:
            st.error(f"Error grouping results: {e}")
            groupby_results_df = None
        if scorer_name == "Cluster":
            try:
                scores_cluster = scorer.aggregate_df(groupby_results_df)
                scorer._fragments_df.to_csv(
                    f"{scorer._output_path}/groupby_aggregated_clusters_with_score.csv",
                    index=False,
                )  # Generated by Copilot
            except Exception as e:
                st.error(f"Error aggregating clusters: {e}")
                scores_cluster = None
        return df_scores
    return None


def get_scorer_properties_ui(scorer_name):
    # Generated by Copilot
    """Display UI for scorer properties and return a dict of properties."""
    props = {}
    if scorer_name == "Ngram":
        props["ngram_size"] = st.sidebar.number_input(
            "Ngram size", min_value=2, max_value=20, value=10, step=1
        )
    if scorer_name in ["Ngram", "Scaffold", "Cluster", "Original"]:
        props["output_path"] = st.session_state.output_path
        props["min_count_fragments"] = st.sidebar.number_input(
            "min_count_fragments", min_value=0, max_value=10, value=0, step=1
        )
    if scorer_name == "Scaffold":
        props["scaffold_type"] = st.sidebar.selectbox(
            "Scaffold type",
            ["csk_bm", "csk", "bajorath", "murcko", "real_bm"],
            index=0,
        )
    if scorer_name == "Cluster":
        props["threshold"] = st.sidebar.number_input(
            "Cluster threshold",
            min_value=0.0,
            max_value=1.0,
            value=0.25,
            step=0.01,
        )
    if scorer_name == "Original":
        props["threshold"] = st.sidebar.number_input(
            "Original similarity threshold",
            min_value=0.0,
            max_value=1.0,
            value=0.3,
            step=0.01,
        )
        props["reference_csv"] = st.sidebar.text_input(
            "Reference CSV path",
            value="/media/mohammed/Work/Navi_diversity/examples/df_original.csv",
        )
    if scorer_name == "Fragments":
        props["output_path"] = st.session_state.output_path
        props["min_count_fragments"] = st.sidebar.number_input(
            "min_count_fragments", min_value=1, max_value=10, value=1, step=1
        )
    return props


def selection_criteria_ui():
    """Example:
    selection_criteria = {
        "Count_perc_per_molecule": 1,
        "Count_perc": 1,
        "diff_median_score": -5,
        "median_score_fragment": 0,
    }
    """
    col_selection_criteria = st.sidebar.columns(3)
    with col_selection_criteria[0]:
        count_perc_per_molecule = st.sidebar.number_input(
            "Count percentage per molecule",
            min_value=0.0,
            max_value=100.0,
            value=1.0,
            step=1.0,
        )
    with col_selection_criteria[1]:
        count_perc = st.sidebar.number_input(
            "Median score for molecule containing fragment",
            min_value=0.0,
            max_value=100.0,
            value=1.0,
            step=1.0,
        )
    with col_selection_criteria[2]:
        diff_median_score = st.sidebar.number_input(
            "Difference median score",
            min_value=-100.0,
            max_value=100.0,
            value=-5.0,
            step=1.0,
        )
    selection_criteria = {
        "Count_perc_per_molecule": count_perc_per_molecule,
        "Count_perc": count_perc,
        "diff_median_score": diff_median_score,
    }
    return selection_criteria
