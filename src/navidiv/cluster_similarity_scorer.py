# Generated by Copilot

import numpy as np
import pandas as pd
from rdkit import Chem, DataStructs
from rdkit.Chem import rdFingerprintGenerator

from navidiv.scorer import BaseScore


def get_fingerprints(molecules):
    """Generate Morgan fingerprints for a list of molecules."""
    mfpgen = rdFingerprintGenerator.GetMorganGenerator(
        radius=5, fpSize=2048, countSimulation=True
    )
    fingerprints = [mfpgen.GetFingerprint(mol) for mol in molecules]
    return fingerprints


def calculate_similarity(fp_list1, fp_list2):
    """Calculate the Tanimoto similarity between two sets of fingerprints."""
    return np.array(
        [DataStructs.BulkTanimotoSimilarity(fp1, fp_list2) for fp1 in fp_list1]
    )


class ClusterSimScorer(BaseScore):
    """Handles fragment scoring and analysis for molecular datasets."""

    def __init__(
        self,
        threshold: float = 0.8,
        output_path: str | None = None,
    ) -> None:
        """Initialize FragmentScore.

        Args:
            min_count_fragments (int): Minimum count for fragments to be
                considered.
            output_path (str | None): Path to save output files.
        """
        super().__init__(output_path=output_path)
        self._csv_name = "clusters"
        self._similarity = []
        self.threshold = threshold
        self._min_count_fragments = 0

    def get_clusters(self, similarity):
        """Get clusters of similar molecules based on a similarity threshold."""
        # np.fill_diagonal(similarity, 0)
        clusters = set()

        for i in range(similarity.shape[0]):
            if not np.any(similarity[i, :i] > self.threshold):
                clusters.add(i)
        return clusters

    def get_count(self, smiles_list: list[str]) -> tuple[pd.DataFrame, None]:
        """Calculate the percentage of each fragment in the dataset.

        Args:
            smiles_list (list[str]): List of SMILES strings.

        Returns:
            tuple: DataFrame with fragment info, None (for compatibility)
        """
        # if not hasattr(self, "_mol_smiles"):
        self._mol_smiles = [
            Chem.MolFromSmiles(smiles)
            for smiles in smiles_list
            if smiles != "None"
        ]
        self._mol_smiles = [mol for mol in self._mol_smiles if mol is not None]
        self._smiles_list = [
            smiles
            for smiles in smiles_list
            if smiles != "None" and Chem.MolFromSmiles(smiles) is not None
        ]

        search_fps = get_fingerprints(self._mol_smiles)

        self._similarity_to_itself = calculate_similarity(
            search_fps, search_fps
        )
        df_similarity = pd.DataFrame(
            self._similarity_to_itself,
        )
        df_similarity.to_csv(self._output_path + "/similarity.csv")
        clusters = self.get_clusters(self._similarity_to_itself)
        clusters_smiles = [self._smiles_list[i] for i in clusters]
        fragments, over_represented_fragments = self._from_list_to_count_df(
            self._smiles_list,
            clusters_smiles,
            total_number_of_ngrams=len(self._smiles_list),
        )
        self._fragments_df = fragments
        return fragments, over_represented_fragments

    def _cout_substructure_in_smiles(self, smiles_list, ngram):
        """Check if ngram is in smiles"""
        # np.fill_diagonal(self._similarity_to_itself, 0)
        ngram_index = self._smiles_list.index(ngram)
        return 1 + len(
            [
                i
                for i in range(self._similarity_to_itself.shape[0])
                if self._similarity_to_itself[ngram_index, i] > self.threshold
            ]
        )

    def _comparison_function(
        self,
        smiles: str | None = None,
        fragment: str | None = None,
        mol: Chem.Mol | None = None,
    ) -> bool:
        """Check if the fragment is present in the SMILES string or molecule."""
        if fragment in self._smiles_list:
            ngram_index = self._smiles_list.index(fragment)
        else:
            return False
        if smiles in self._smiles_list:
            smiles_index = self._smiles_list.index(smiles)
        else:
            return False
        # print(f"ngram_index: {ngram_index}, smiles_index: {smiles_index}")
        return (
            self._similarity_to_itself[ngram_index, smiles_index]
            > self.threshold
        )

    def additional_metrics(self):
        """Calculate additional metrics for the scorer."""
        np.fill_diagonal(self._similarity_to_itself, 0)
        mean_distance = np.mean(self._similarity_to_itself)
        std_distance = np.std(self._similarity_to_itself)
        return {
            "mean_distance": mean_distance,
            "std_distance": std_distance,
        }

    def aggregate_df(self, df: pd.DataFrame) -> pd.DataFrame:
        """Aggregate the DataFrame by clusters.

        this is a funciton to be used one a groupedby Dataframe of clusters with steps.
        """

        def process_fragment(
            fragment: str, smiles_list: list[str]
        ) -> list[float]:
            contains_fragment_dict = {}
            for smiles in smiles_list:
                if smiles not in contains_fragment_dict:
                    contains_fragment_dict[smiles] = self._comparison_function(
                        smiles=smiles, fragment=fragment
                    )
            molecules_countaining_fragment = [
                smiles
                for smiles in smiles_list
                if contains_fragment_dict[smiles]
            ]  # type: ignore

            return molecules_countaining_fragment

        smiles_list = df["Substructure"].tolist()
        self.get_count(smiles_list)
        self._fragments_df = self._fragments_df[
            self._fragments_df["Count"] > self._min_count_fragments
        ]
        self._fragments_df["molecules_countaining_fragment"] = (
            self._fragments_df[
                "Substructure"
            ].apply(lambda x: process_fragment(x, self._smiles_list))
        )

        if self.add_num_atoms:
            num_atoms = []
            for substructure in self._fragments_df["Substructure"]:
                mol = Chem.MolFromSmarts(substructure)
                if mol is not None:
                    num_atoms.append(mol.GetNumAtoms())
                else:
                    num_atoms.append(0)
            self._fragments_df["num_atoms"] = num_atoms
        self._fragments_df["Mean score cluster"] = self._fragments_df.apply(
            lambda x: df[
                df["Substructure"].isin(x["molecules_countaining_fragment"])
            ]["median_score_fragment_mean"].mean(),
            axis=1,
        )
        self._fragments_df[
            ["Molecules containing fragment", "Number of Molecules in Cluster"]
        ] = flatten_dataframe_to_unique_column(
            self._fragments_df.apply(
                lambda x: df[
                    df["Substructure"].isin(
                        x["molecules_countaining_fragment"]
                    )
                ]["Molecules containing fragment"],
                axis=1,
            )
        )
        self._fragments_df[["Steps"]] = flatten_dataframe_to_column(
            self._fragments_df.apply(
                lambda x: df[
                    df["Substructure"].isin(
                        x["molecules_countaining_fragment"]
                    )
                ]["step_list"],
                axis=1,
            )
        )
        self._fragments_df[["Number of Molecules with fragment"]] = (
            flatten_dataframe_to_column(
                self._fragments_df.apply(
                    lambda x: df[
                        df["Substructure"].isin(
                            x["molecules_countaining_fragment"]
                        )
                    ]["Number of Molecules with Substructure List"],
                    axis=1,
                )
            )
        )

        self._fragments_df = self._fragments_df[
            [
                "Substructure",
                "Molecules containing fragment",
                "Number of Molecules in Cluster",
                "Mean score cluster",
                "Steps",
                "Number of Molecules with fragment",
            ]
        ]
        return self._fragments_df


def flatten_dataframe_to_unique_column(df: pd.DataFrame) -> pd.DataFrame:
    """Flatten all non-NaN sets from a DataFrame into a single set,
    and return a DataFrame with unique fragments and their count.
    """
    mat = df.to_numpy()
    unique_items_list = []
    for i in range(mat.shape[0]):
        unique_items = set()
        for j in range(mat.shape[1]):
            if isinstance(mat[i, j], str):
                unique_items.update(eval(mat[i, j]))
            elif isinstance(mat[i, j], set):
                unique_items.update(mat[i, j])

        unique_items_list.append(unique_items)

    return pd.DataFrame(
        {
            "unique_fragments": [x for x in unique_items_list],
            "number of molecules": [len(x) for x in unique_items_list],
        }
    )


def flatten_dataframe_to_column(df: pd.DataFrame) -> pd.DataFrame:
    """Flatten all non-NaN sets from a DataFrame into a single set,
    and return a DataFrame with unique fragments and their count.
    """
    mat = df.to_numpy()
    unique_items_list = []
    for i in range(mat.shape[0]):
        unique_items = []
        for j in range(mat.shape[1]):
            if isinstance(mat[i, j], str):
                unique_items.extend(eval(mat[i, j]))
            elif isinstance(mat[i, j], list):
                unique_items.extend(mat[i, j])

        unique_items_list.append(unique_items)

    return pd.DataFrame(
        {
            "unique_fragments": [list(x) for x in unique_items_list],
        }
    )


def aggregate_list_column(df: pd.DataFrame, column_name: str) -> pd.DataFrame:
    """Aggregate a list column in a DataFrame."""
    df[column_name] = df[column_name].apply(eval)
    df[column_name] = df[column_name].apply(lambda x: list(set(x)))
    return df.groupby(column_name).size().reset_index(name="Count")
